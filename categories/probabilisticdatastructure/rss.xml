<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
      <title>Aurora - ProbabilisticDataStructure</title>
        <link>https://charmer.fun</link>
        <description>Sidere mens eadem mutato</description>
        <generator>Zola</generator>
        <language>zh</language>
        <atom:link href="https://charmer.fun/categories/probabilisticdatastructure/rss.xml" rel="self" type="application/rss+xml"/>
        <lastBuildDate>Tue, 15 Mar 2022 22:58:53 +0800</lastBuildDate>
        <item>
            <title>Count-Min Sketch</title>
            <pubDate>Tue, 15 Mar 2022 22:58:53 +0800</pubDate>
            <link>https://charmer.fun/posts/count-min-sketch/</link>
            <guid>https://charmer.fun/posts/count-min-sketch/</guid>
            <description>&lt;p&gt;本文将介绍&lt;a href=&quot;&#x2F;categories&#x2F;probabilisticdatastructure&#x2F;&quot;&gt;概率性数据结构&lt;&#x2F;a&gt;这个专题的第三个数据结构，实际上它只是&lt;a href=&quot;&#x2F;posts&#x2F;bloom-filter-1&#x2F;&quot;&gt;布隆过滤器&lt;&#x2F;a&gt;的一个变体，它的结构几乎和计数布隆过滤器一致，但是解决不同的问题。&lt;&#x2F;p&gt;
&lt;p&gt;在上篇文章&lt;a href=&quot;&#x2F;posts&#x2F;hyper-log-log&#x2F;&quot;&gt;HyperLogLog&lt;&#x2F;a&gt;中我们提到基数统计问题，换个问题，如果要统计海量的数据流中每个元素的出现次数呢？&lt;&#x2F;p&gt;
&lt;p&gt;一看这个问题我们自然又会想到hash数据结构，但相比于&lt;a href=&quot;&#x2F;posts&#x2F;hyper-log-log&#x2F;#hashset-bitmap&quot;&gt;HyperLogLog&lt;&#x2F;a&gt;一文中使用的HashSet，我们需要使用HashMap用value作为counter计数。&lt;&#x2F;p&gt;
&lt;p&gt;理所当然，原型方案只是用于提供一个解决问题的思路与方式，我们需要考虑它的局限。假设流中有千万个数据，若它们都不一样，那HashMap中就有千万个键值对，空间占用可想而知。本文介绍的Count-Min Sketch(CMS)就是利用概率的方式解决空间消耗过大问题。&lt;&#x2F;p&gt;
&lt;p&gt;⚠️ 相比于论文&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#1&quot;&gt;1&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;，本文的查询只涉及point query，而不涉及range query和inner product query。&lt;&#x2F;p&gt;
&lt;p&gt;可以先看这个视频对本文有直观的认识&lt;&#x2F;p&gt;
&lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;mPxslXpg8wA&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;
&lt;h2 id=&quot;li-yong-hashjie-sheng-kong-jian&quot;&gt;利用Hash节省空间&lt;&#x2F;h2&gt;
&lt;p&gt;首先想到的方案是利用Hash函数和数组，将元素Hash结果作为index，在数组中统计，这样就可以节省掉HashMap中存储key的空间。&lt;&#x2F;p&gt;
&lt;p&gt;首先准备一个Hash函数$h$，一个长度为$w$的数组$count$。&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;初始化时将$count$数组元素初始化为0：$count[i] = 0, 0\le{}i\lt{}w$&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;添加元素时，对元素$a$计算Hash值并对$w$取模，作为下标将$count$数组中对应元素自增：$count[h(a)\mod{}w]+=1$。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;oliverdding&#x2F;imaw.io&#x2F;main&#x2F;single-array-in-count-min-sketch.drawio.svg&quot; alt=&quot;插入元素示例&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;查询元素时，同样方式获取下标然后返回数组元素内容：$count[h(a)\mod{}w]$。&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;这种方式有一个致命缺陷：Hash碰撞。一旦发生Hash碰撞，意味着碰撞的两个元素的统计值（两个元素的个数总和）会大于实际值，也就是说返回的值一定是上限，大于等于真实值。想缓解这个问题，看起来我们只能分配一个足够大的数组，并且运用一些Hash碰撞的解决办法。那么有没有更简单的办法呢？&lt;&#x2F;p&gt;
&lt;h2 id=&quot;cms&quot;&gt;CMS&lt;&#x2F;h2&gt;
&lt;p&gt;既然一个Hash函数+数组容易发生碰撞，那么如果引入多个Hash函数与多个数组呢？这就是CMS的解决办法。&lt;&#x2F;p&gt;
&lt;p&gt;首先准备$d$个Hash函数$h_1,h_2,...,h_d$，一个宽度为$w$深度为$d$的二维数组$count$。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;oliverdding&#x2F;imaw.io&#x2F;main&#x2F;empty-cms.drawio.svg&quot; alt=&quot;空count数组&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;初始化时将$count$数组元素初始化为0：$count[i, j] = 0, 0\le{}i\lt{}w, 0\le{}j\lt{}d$&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;添加元素时，对元素$a$计算$d$个Hash值，并将二维数组中Hash函数对应的一维数组的元素自增：$count[i, h_i(a)\mod{}w]+=1$（$0\le{}i\lt{}d$的全部元素）&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;oliverdding&#x2F;imaw.io&#x2F;main&#x2F;cms-insert.drawio.svg&quot; alt=&quot;插入元素示例&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;查询元素时，同样获得$d$个Hash值，并取得对应的$d$个元素中的最小值：$min_{i=0}^{d-1}count[i, h_i(a)\mod{}w]$（$0\le{}i\lt{}d$的全部元素）&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;oliverdding&#x2F;imaw.io&#x2F;main&#x2F;cms-query.drawio.svg&quot; alt=&quot;查询元素示例&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;通过多个Hash函数与多个数组（一维数组）的方式，尽可能避免Hash碰撞的影响，这就是CMS的全部内容，一般将底层的二维数组称为sketch。&lt;&#x2F;p&gt;
&lt;p&gt;可是如何能证明它的的概率可用？$d$、$w$应该取什么值呢？&lt;&#x2F;p&gt;
&lt;h2 id=&quot;li-lun-bu-fen&quot;&gt;理论部分&lt;&#x2F;h2&gt;
&lt;p&gt;论文引入了两个符号$\varepsilon$和$\delta$，这两个都是用户根据自己可用资源和所需目标给定的值，除此之外令$\parallel{}count\parallel{}_1$为sketch所有元素的总和。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;理论&lt;&#x2F;strong&gt;： 用户设定$\varepsilon$和$\delta$后，可以根据公式$$w=\lceil{}\frac{e}{\varepsilon}\rceil{}$$和$$d=\lceil{}ln\frac{1}{\delta}\rceil{}$$计算$w$和$d$的值。论文&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#1&quot;&gt;1&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;证明，可以在$1-\delta$的概率内，误差最大为$\varepsilon{}\ast{}\parallel{}count\parallel{}_1$&lt;&#x2F;p&gt;
&lt;p&gt;主观上体会，增加新的Hash函数可以降低超出最大误差的概率，因为新增后还是超出最大误差需要新增的Hash函数也发生Hash碰撞，而不同Hash函数间相互独立，具有指数效应。&lt;&#x2F;p&gt;
&lt;p&gt;增加宽度有助于分散计数，降低最大误差，但是这只是线性的。&lt;&#x2F;p&gt;
&lt;p&gt;一般而言，sketch的宽度（$w$）会远远大于深度（$d$），过多的Hash函数（$d$）会造成额外的开销。同时，随着Hash函数（$d$）增多，$\delta$会极速缩小。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;can-kao&quot;&gt;参考&lt;&#x2F;h2&gt;
&lt;div class=&quot;footnote-definition&quot; id=&quot;1&quot;&gt;&lt;sup class=&quot;footnote-definition-label&quot;&gt;1&lt;&#x2F;sup&gt;
&lt;p&gt;Graham Cormode and S. Muthukrishnan. 2005. An improved data stream summary: the count-min sketch and its applications. Journal of Algorithms 55, 1 (2005), 58–75&lt;&#x2F;p&gt;
&lt;&#x2F;div&gt;
</description>
        </item>
        <item>
            <title>HyperLogLog</title>
            <pubDate>Sun, 27 Feb 2022 17:15:52 +0800</pubDate>
            <link>https://charmer.fun/posts/hyper-log-log/</link>
            <guid>https://charmer.fun/posts/hyper-log-log/</guid>
            <description>&lt;p&gt;基数统计问题（&lt;em&gt;Count-distinct problem&lt;&#x2F;em&gt;）是指在具有重复元素的数据流中找到不同元素的数目的，该问题有许多场景，比如统计通过某个路由器的ip数量、统计访问某网站的用户数以及数据库总某一字段的基数。&lt;&#x2F;p&gt;
&lt;p&gt;可以先看这个视频对本文有直观的认识&lt;&#x2F;p&gt;
&lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;jD2d7jr7z1Q&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;
&lt;h2 id=&quot;b-tree&quot;&gt;B-tree&lt;&#x2F;h2&gt;
&lt;p&gt;首先，基数统计的难点有：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;查找元素&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;插入元素&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;由于海量数据存储于磁盘，我们自然会考虑到B树。这里不细展开，只说优缺点。虽然B树查找、插入效率与内存占用上都很均衡，但是每一条记录实际都被完整存储，对于基数统计而言是没必要的；并且B树之间无法&lt;strong&gt;合并&lt;&#x2F;strong&gt;，对于网站场景，想统计两个页面访问用户数时，除非特意建立两个页面的B树，否则无法办到。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;hashset-bitmap&quot;&gt;HashSet&#x2F;Bitmap&lt;&#x2F;h2&gt;
&lt;p&gt;为了克服B树遇到的问题，我们自然想到用HashSet减少存储的key值，更进一步将元数据内容转为数字作为index，将key也省略掉，也就是使用Bitmap来统计。既可以快速查找、插入元素，也可以合并。&lt;&#x2F;p&gt;
&lt;p&gt;但是Bitmap有着天然的缺陷，它的长度预先设置，取决于数据的范围（也就是值域，domain）。假设我有10GB个数需要统计，那就需要分配10GB的Bitmap，就算这10GB的数全都是一个。&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里补充一句，可以使用压缩位图来&lt;strong&gt;缓解&lt;&#x2F;strong&gt;这个问题，比如roaring-bitmap。&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h2 id=&quot;linear-counting-lc&quot;&gt;Linear Counting(LC)&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#1&quot;&gt;1&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;到这里我们可以发现，想要查找快、插入快、可以合并且内存占用低的数据结构恐怕人类还没掌握。不妨思考人类的常用手段：近似，我们可以试着利用概率去估计出基数。&lt;&#x2F;p&gt;
&lt;p&gt;需要：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;q个输入元素$\overrightarrow{a}={ a_0, a_1, a_2, .., a_{q-1}}$&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;长度为m的Bitmap&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;一个结果服从均匀分布的hash函数，值域[0, m-1]&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;输出&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;元素集合$\overrightarrow{a}$的基数估计$n$&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;特点&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;空间复杂度相对于Bitmap仅仅有常数级别降低，因此仍然不适用于大数据集场景&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;ji-ben-si-xiang&quot;&gt;基本思想&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;oliverdding&#x2F;imaw.io&#x2F;main&#x2F;linear_counting.drawio.svg&quot; alt=&quot;LC图示&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;输入元素集合$\overrightarrow{a}$服从均匀分布，其hash结果$hash(\overrightarrow{a})={b_0,b_1,…,b_{q-1}},0\le{}b_i \le{m-1}也$服从均匀分布。将Bitmap中下标$b_i, 0\le{}i\le{}q$位置1，统计Bitmap中仍为0的个数记为$u$，则$n$的最大释然估计$\hat{n}=-mlog(\dfrac{u}{m})$&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;数学证明非常庞大复杂，请读者自行阅读论文，我就不班门弄斧了。&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h2 id=&quot;loglog-counting-llc&quot;&gt;LogLog Counting(LLC)&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#2&quot;&gt;2&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;LC算法空间利用率仍然不高，是否可以进一步优化呢？这就是LLC。&lt;&#x2F;p&gt;
&lt;p&gt;让我借用论文的例子，对于伯努利过程A：不停抛掷一枚均匀硬币，出现反面则继续抛掷，出现正面则停止抛掷，抛掷出的反面次数为$k$。可以得知$P_A(x=k)=(\frac{1}{2})^{k}\quad{}k=0,1,2,3,4,5,…$&lt;&#x2F;p&gt;
&lt;p&gt;思考两个问题：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;进行$n$次过程A，每一次过程的总抛掷次数都不大于某个常数$k_{max}$的概率为？&lt;&#x2F;p&gt;
&lt;p&gt;易得$P_1(x\le{}k_{max})=[1-(\frac{1}{2})^{k_{max}}]^n$&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;进行n次过程A，至少有一次过程的总抛掷次数等于某个常数$k_{max}$的概率为？&lt;&#x2F;p&gt;
&lt;p&gt;易得$P_2(x=k_{max})=1 – P_1(x\le{}k_{max}–1)=1-[1-(\frac{1}{2})^{k_{max}-1}]^n$&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;由于&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$n &amp;gt;&amp;gt; 2^{k_{max}}, \quad P_1(x \leq k_{max}) \approx 0$&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;$n &amp;lt;&amp;lt; 2^{k_{max}}, \quad P_2(x = k_{max}) \approx 0$&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;因此我们可以认为n和$2^{k_{max}}$相近～&lt;&#x2F;p&gt;
&lt;p&gt;需要：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;输入元素集合&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;分桶位数$l$，得到$m=2^l$个桶&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;一个结果服从均匀分布的hash函数，结果长度为$L$&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;输出&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;元素集合的基数估计$n$&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;特点&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;标准差为$\dfrac{1.3}{\sqrt{2^l}}$&lt;&#x2F;li&gt;
&lt;li&gt;空间复杂度$O(log(log(n)))$&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;ji-ben-si-xiang-1&quot;&gt;基本思想&lt;&#x2F;h3&gt;
&lt;p&gt;说了这么多，那么到底有什么用呢？接下来我就从易于理解的方式介绍LLC。&lt;&#x2F;p&gt;
&lt;p&gt;在hash的过程，若hash结果固定，而且hash函数随机性很好，hash函数不尝试碰撞，那么可以认为每一个元素进行哈希后的值转化为2进制串的结果是一个伯努利过程。因此$k_{max}$为从二进制字串高位开始第一个1的位置，$2^{k_{max}}$为基数n的一个估计。&lt;&#x2F;p&gt;
&lt;p&gt;但是单次实验偶然性造成的误差会很大，要如何避免呢？增加几个hash函数，每次插入时并行计算？LLC采用了分桶计算的方式。将hash串前$l$位作为bucket编号，后面的位继续做LLC估算（由于伯努利过程每次实验相互独立，因此去掉前面$l$位并不影响后续的伯努利过程）。假设分了m个桶，第$i, 0\le{}i\le{}m-1$个bucket的第一个1的位置最大值为$M_i$，则LLC的结果为$\hat{n}=2^{\frac{\sum_{i=0}^{m-1}(M_i)}{m}}$。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;oliverdding&#x2F;imaw.io&#x2F;main&#x2F;loglog_count.drawio.svg&quot; alt=&quot;分桶重复实验&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;本节介绍的LLC并不是无偏估计，更逻辑严密的推导过程详见论文。&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h2 id=&quot;hyperloglog-hll&quot;&gt;HyperLogLog(HLL)&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#3&quot;&gt;3&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;HLL是LLC的改进，用&lt;strong&gt;调和平均数&lt;&#x2F;strong&gt;取代了&lt;strong&gt;算术平均数&lt;&#x2F;strong&gt;。&lt;&#x2F;p&gt;
&lt;p&gt;算术平均数对于离群值十分敏感，在基数总数比较小时，可能会存在比较多的空桶，会干扰平均数的稳定性。&lt;&#x2F;p&gt;
&lt;p&gt;HLL的结果不加证明给出$\hat{n}=\dfrac{\alpha_m m^2}{\sum 2^{-M}}$，其中$\alpha_m$为后续无偏渐进化的参数$\alpha_m=(m\int _0^\infty (log_2(\frac{2+u}{1+u}))^m du)^{-1}$&lt;&#x2F;p&gt;
&lt;p&gt;特点&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;标准差为$\dfrac{1.04}{\sqrt{m}}$&lt;&#x2F;li&gt;
&lt;li&gt;空间复杂度O(log(log(n)))&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;HLL的代码实践可以参考&lt;a rel=&quot;noopener nofollow noreferrer&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;addthis&#x2F;stream-lib&#x2F;blob&#x2F;master&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;clearspring&#x2F;analytics&#x2F;stream&#x2F;cardinality&#x2F;HyperLogLog.java&quot;&gt;stream-lib&#x2F;HyperLogLog.java at master · addthis&#x2F;stream-lib (github.com)&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;can-kao&quot;&gt;参考&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#1&quot;&gt;1&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt; Whang, Kyu-Young et al. &amp;quot;A linear-time probabilistic counting algorithm for database applications.&amp;quot; &lt;em&gt;ACM Trans. Database Syst.&lt;&#x2F;em&gt; 15 (1990): 208-229.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#2&quot;&gt;2&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt; Marianne Durand, Philippe Flajolet. &amp;quot;Loglog Counting of Large Cardinalities (Extended Abstract)&amp;quot;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#3&quot;&gt;3&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt; Philippe Flajolet and Éric Fusy and Olivier Gandouet and Frédéric Meunier. &amp;quot;HyperLogLog: the analysis of a near-optimal
cardinality estimation algorithm&amp;quot;&lt;&#x2F;p&gt;
</description>
        </item>
        <item>
            <title>可扩展布隆过滤器</title>
            <pubDate>Tue, 15 Feb 2022 14:00:16 +0800</pubDate>
            <link>https://charmer.fun/posts/bloom-filter-2/</link>
            <guid>https://charmer.fun/posts/bloom-filter-2/</guid>
            <description>&lt;h2 id=&quot;jie-shao&quot;&gt;介绍&lt;&#x2F;h2&gt;
&lt;p&gt;在上篇博文&lt;a href=&quot;&#x2F;posts&#x2F;bloom-filter-1&#x2F;&quot;&gt;基础布隆过滤器&lt;&#x2F;a&gt;中介绍了基础的bloom filter以及相关数学推导，最后给出了应用最佳实践。在文章最后提及基础布隆过滤器无法在保证false positive率的同时扩展存储，必须在使用前预估集合大小（n）。但是在很多情况下，集合大小无法预估，这就需要使用本篇介绍的布隆过滤器变体。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;bu-long-guo-lu-qi-bian-ti&quot;&gt;布隆过滤器变体&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;oliverdding&#x2F;imaw.io&#x2F;main&#x2F;variant_bloom_filter.drawio.svg&quot; alt=&quot;布隆过滤器变体&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;布隆过滤器变体由以下两部分构成：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;M位的位图：&lt;code&gt;bitmap&lt;&#x2F;code&gt;&lt;&#x2F;li&gt;
&lt;li&gt;k个相互独立的hash函数：&lt;code&gt;h1, h2, ..., hk&lt;&#x2F;code&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;其中，M位的位图被k等分，每个slice长度为m，即$m=\frac{M}{k}$。&lt;&#x2F;p&gt;
&lt;p&gt;与基础布隆过滤器不同的是，每个hash函数独享自己对应的slice（而不是全部位图）。&lt;&#x2F;p&gt;
&lt;p&gt;这种变体提高了健壮性，并且支持并发处理。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;shu-xue-tui-dao&quot;&gt;数学推导&lt;&#x2F;h3&gt;
&lt;p&gt;对于某个slice，插入1个元素后，某一个位被置1、置0的概率为$\frac{1}{m}$、$1-\frac{1}{m}$&lt;&#x2F;p&gt;
&lt;p&gt;当插入n个元素后，某一位被置0、置1的概率是$(1-\frac{1}{m})^n$、$1-(1-\frac{1}{m})^n$&lt;&#x2F;p&gt;
&lt;p&gt;同样使用自然对数e的计算公式$$\lim_{x \to \infty}{(1-\frac{1}{x})^{-x}}=e$$&lt;&#x2F;p&gt;
&lt;p&gt;插入n个元素后某一位被置1的概率可以简化为$$p\approx{}1-e^{-\frac{n}{m}}$$&lt;&#x2F;p&gt;
&lt;p&gt;于是得到$$n\approx{}-mln(1-p)$$&lt;&#x2F;p&gt;
&lt;p&gt;又由公式$M=km$和$P=p^k$，我们推导出$m=M\frac{ln(p)}{ln(P)}$，因此有$$n\approx{}M\frac{ln(p)ln(1-p)}{-ln(P)}$$&lt;&#x2F;p&gt;
&lt;p&gt;对于给定的纳伪率$P$和位图大小M，当$p=\frac{1}{2}$时n取到最大值，此时能容纳最多的元素。$p$代表一个slice的饱和程度，我们得知slice半饱和时最好，对于$p=\frac{1}{2}$我们可以简化上面的公式为$$n\approx{}M\frac{(ln(2)^2)}{\lvert{}ln(P)\rvert{}}$$&lt;&#x2F;p&gt;
&lt;p&gt;P是给定的纳伪率，因此对于这个布隆过滤器变体而言，可以容纳的元素数量n是和位图大小M呈线性关系。&lt;&#x2F;p&gt;
&lt;p&gt;最后由$P=p^k$和$p=\frac{1}{2}$我们推导出$$k=log_{2}\frac{1}{P}$$&lt;&#x2F;p&gt;
&lt;h3 id=&quot;ying-yong&quot;&gt;应用&lt;&#x2F;h3&gt;
&lt;h4 id=&quot;yi-zhi-n-he-p&quot;&gt;已知$n$和$P$&lt;&#x2F;h4&gt;
&lt;ol&gt;
&lt;li&gt;根据公式$k=\lceil{}log_{2}\frac{1}{P}\rceil{}$计算k的值&lt;&#x2F;li&gt;
&lt;li&gt;根据公式$m\approx{}\lceil{}\frac{n\lvert{}ln(P)\rvert{}}{kln^2(2)}\rceil{}$计算m的值&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;ke-kuo-zhan-de-bu-long-guo-lu-qi&quot;&gt;可扩展的布隆过滤器&lt;&#x2F;h2&gt;
&lt;p&gt;本篇介绍的可扩展布隆过滤器（Scalable Bloom Filter, SBF）基于前文提及的布隆过滤器变体，有两个关键部分：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;SBF由一个或多个布隆过滤器组成。&lt;&#x2F;li&gt;
&lt;li&gt;后续的布隆过滤器的纳伪率成等比数列缩小，以保证整体纳伪率保持在一个数值内。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;可扩展布隆过滤器同样存在两个操作：插入、查询。&lt;&#x2F;p&gt;
&lt;p&gt;当插入时，从过滤器列表最后一个过滤器插入新元素，并在“满了”时扩展过滤器列表。&lt;&#x2F;p&gt;
&lt;p&gt;但查询时，从前往后依次查询，每个过滤器都返回不存在时，则表明元素不存在，否则返回存在。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;shu-xue-tui-dao-1&quot;&gt;数学推导&lt;&#x2F;h3&gt;
&lt;p&gt;SBF创建时只有一个布隆过滤器，$k_0$个slice，纳伪率为$P_0$。当这个过滤器满了，添加新的过滤器（$k_1$个slice，纳伪率为$P_1=P_{0}r$，且$0&amp;lt;r&amp;lt;1$）。&lt;&#x2F;p&gt;
&lt;p&gt;当SBF存在$l$个过滤器后，其纳伪率为$$P=1-\prod_{i=0}^{l-1}(1-P_{0}r^i)$$&lt;&#x2F;p&gt;
&lt;p&gt;由于有缩放公式$$1-\prod_{i}(1-P_i)\le{}\sum_{i}P_i$$&lt;&#x2F;p&gt;
&lt;p&gt;我们可以得到P的上限$$P\le{}\sum_{i=0}^{l-1}P_{0}r^{i}\le{}\lim_{l \to \infty}\sum_{i=0}^{l-1}P_{0}r^i$$&lt;&#x2F;p&gt;
&lt;p&gt;因此有$$P\le{}P_{0}\frac{1}{1-r}$$&lt;&#x2F;p&gt;
&lt;p&gt;每个过滤器的slice长度为$$k_{0}=log_{2}(P_{0}^{-1})$$，$$k_{i}=log_{2}(P_{i}^{-1})=k_{0}+ilog_{2}(r^{-1}) \tag{1}$$&lt;&#x2F;p&gt;
&lt;p&gt;为了保证每个k_i都是整数，我们自然会想让$r=\frac{1}{2}$，此时有$$k_i=k_0+i$$，意味着每添加一个过滤器都需要扩充一个slice。此时SBF的整体纳伪率为$$P\le{}2P_0=2^{1-k_0}$$&lt;&#x2F;p&gt;
&lt;p&gt;论文证明了如果$r\lt{}0.5$，尽管小量数据时使用空间大于$r=0.5$，随着空间增长空间使用反而更小。论文实验证明，r取0.8～0.9时为最佳。&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#1&quot;&gt;1&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;&lt;&#x2F;p&gt;
&lt;p&gt;事实上，后续添加的过滤器的纳伪率$P_i$只要低于整体纳伪率，则可保证整体纳伪率不增加。因此$k_i$的选取可以更加灵活，而不局限于(1)的公式。由于$P_i$和$k_i$成反比，只要$k_i$选取大于(1)的值即可保证$P_i$小。这里为了简化我们可以使用等比数列。假设k的取值为$P_0, P_{0}r, P_{0}r^2,...,P_{0}r^{l-1}$，此时过滤器可以存储的变量数$n_i$大约为$$n_i\approx{}m_{0}s^{i}ln(2)$$，有$l$个过滤器的SBF可以存储约$(ln2)m_{0}\sum_{i=0}^{l-1}s^i$个元素。&lt;&#x2F;p&gt;
&lt;p&gt;论文证明对于缓慢增长的SBF可以考虑设置$s=2$，对于快速增长的过滤器可以设置$s=4$。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;ying-yong-1&quot;&gt;应用&lt;&#x2F;h3&gt;
&lt;h4 id=&quot;yi-zhi-p&quot;&gt;已知$P$&lt;&#x2F;h4&gt;
&lt;ol&gt;
&lt;li&gt;考虑使用$n=8192$构造初始布隆过滤器变体，计算获得$k_0$和m&lt;&#x2F;li&gt;
&lt;li&gt;对于每个后续的$P_i=0.9P_{i-1}$&lt;&#x2F;li&gt;
&lt;li&gt;对于每个后续的过滤器，$k_i=2k_{i-1}$或$k_i=4k_{i-1}$&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;can-kao&quot;&gt;参考&lt;&#x2F;h2&gt;
&lt;div class=&quot;footnote-definition&quot; id=&quot;1&quot;&gt;&lt;sup class=&quot;footnote-definition-label&quot;&gt;1&lt;&#x2F;sup&gt;
&lt;p&gt;Scalable Bloom Filters&lt;&#x2F;p&gt;
&lt;&#x2F;div&gt;
</description>
        </item>
        <item>
            <title>基础布隆过滤器</title>
            <pubDate>Wed, 09 Feb 2022 17:13:10 +0800</pubDate>
            <link>https://charmer.fun/posts/bloom-filter-1/</link>
            <guid>https://charmer.fun/posts/bloom-filter-1/</guid>
            <description>&lt;h2 id=&quot;jie-shao&quot;&gt;介绍&lt;&#x2F;h2&gt;
&lt;p&gt;布隆过滤器（Bloom Filter）用于判断某个元素是否在集合中的一个简单、高效、内存占用低的数据结构，它类似于哈希表，相比于后者，它存在false positive值，但显著地降低了内存占用。这种&lt;a href=&quot;&#x2F;categories&#x2F;probabilisticdatastructure&#x2F;&quot;&gt;概率性数据结构&lt;&#x2F;a&gt;值得体会，以退为进，&lt;em&gt;只要false positive控制在可以允许的范围&lt;&#x2F;em&gt;，资源消耗被大幅降低[4]。&lt;&#x2F;p&gt;
&lt;p&gt;使用布隆过滤器查找key时，返回值可能情况有两种：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;key&lt;strong&gt;不&lt;&#x2F;strong&gt;存在&lt;&#x2F;li&gt;
&lt;li&gt;key&lt;strong&gt;可能&lt;&#x2F;strong&gt;存在（存在、纳伪）&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h3 id=&quot;li-shi&quot;&gt;历史&lt;&#x2F;h3&gt;
&lt;p&gt;布隆过滤器于1970年代被Burton Bloom创造，在查询集合成员存在与否时一般考虑时间成本或空间成本，论文提出第三个优化方向：Allowable Fraction of Errors，也就是说允许一定的误判，来大幅降低空间占用&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#1&quot;&gt;1&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;。之后一段时间布隆过滤器被广泛运用在数据库领域。&lt;&#x2F;p&gt;
&lt;p&gt;之后又有人提出利用布隆过滤器+共享缓存的方式大幅降低缓存服务器的带宽&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#2&quot;&gt;2&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;，自此布隆过滤器在互联网中展现实力&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#3&quot;&gt;3&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;yuan-li&quot;&gt;原理&lt;&#x2F;h3&gt;
&lt;p&gt;布隆过滤器由以下三部分构成：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;n个key&lt;&#x2F;li&gt;
&lt;li&gt;m位的位图：&lt;code&gt;bitmap&lt;&#x2F;code&gt;&lt;&#x2F;li&gt;
&lt;li&gt;k个相互独立的hash函数：&lt;code&gt;h1, h2, ..., hk&lt;&#x2F;code&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;blockquote&gt;
&lt;p&gt;可以用$h_{i}(x)=MD5(x+i)$或者$h_{i}(x)=MD5(x|i)$实现k个无关hash函数&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;需要插入key时，对&lt;code&gt;key = a&lt;&#x2F;code&gt;时，经过k个hash函数后得到k个数&lt;code&gt;h1(a), h2(a), ..., hk(a)&lt;&#x2F;code&gt;，此时将&lt;code&gt;bitmap&lt;&#x2F;code&gt;中对应的位置1。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;oliverdding&#x2F;imaw.io&#x2F;main&#x2F;inserting-key-into-bloom-filter.drawio.svg&quot; alt=&quot;往布隆过滤器插入新key&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;需要查询key时，同样经过k个hash函数得到k个体数，查询&lt;code&gt;bitmap&lt;&#x2F;code&gt;中对应位，若全为1，则key&lt;strong&gt;可能&lt;&#x2F;strong&gt;存在；若任意位为0，则&lt;strong&gt;一定不&lt;&#x2F;strong&gt;存在。（这里可以利用短路减少消耗，若出现0则直接返回不存在）&lt;&#x2F;p&gt;
&lt;p&gt;当key越来越多，&lt;code&gt;bitmap&lt;&#x2F;code&gt;中为1的位越多，对于某个不存在的key，k个hash函数得到的坐标对应&lt;code&gt;bitmap&lt;&#x2F;code&gt;中的值都为1的概率越大，此时就发生false positive。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;li-zi&quot;&gt;例子&lt;&#x2F;h3&gt;
&lt;p&gt;为了直观描述布隆过滤器如何加速查询的，我们用数据库场景来描述。&lt;&#x2F;p&gt;
&lt;p&gt;我们对表中某个字段建立bloom filter，假设有10位的bitmap如下所示：&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;0&lt;&#x2F;th&gt;&lt;th&gt;1&lt;&#x2F;th&gt;&lt;th&gt;2&lt;&#x2F;th&gt;&lt;th&gt;3&lt;&#x2F;th&gt;&lt;th&gt;4&lt;&#x2F;th&gt;&lt;th&gt;5&lt;&#x2F;th&gt;&lt;th&gt;6&lt;&#x2F;th&gt;&lt;th&gt;7&lt;&#x2F;th&gt;&lt;th&gt;8&lt;&#x2F;th&gt;&lt;th&gt;9&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;p&gt;我们使用Fnv和Murmur这两个hash函数。&lt;&#x2F;p&gt;
&lt;p&gt;首先插入字符串&lt;code&gt;hello&lt;&#x2F;code&gt;，计算&lt;code&gt;Fnv=6&lt;&#x2F;code&gt;，&lt;code&gt;Murmur=0&lt;&#x2F;code&gt;，于是bitmap如下所示：&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;0&lt;&#x2F;th&gt;&lt;th&gt;1&lt;&#x2F;th&gt;&lt;th&gt;2&lt;&#x2F;th&gt;&lt;th&gt;3&lt;&#x2F;th&gt;&lt;th&gt;4&lt;&#x2F;th&gt;&lt;th&gt;5&lt;&#x2F;th&gt;&lt;th&gt;6&lt;&#x2F;th&gt;&lt;th&gt;7&lt;&#x2F;th&gt;&lt;th&gt;8&lt;&#x2F;th&gt;&lt;th&gt;9&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;p&gt;接着插入字符串&lt;code&gt;world&lt;&#x2F;code&gt;，计算&lt;code&gt;Fnv=7&lt;&#x2F;code&gt;，&lt;code&gt;Murmur=1&lt;&#x2F;code&gt;，于是bitmap如下所示：&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;0&lt;&#x2F;th&gt;&lt;th&gt;1&lt;&#x2F;th&gt;&lt;th&gt;2&lt;&#x2F;th&gt;&lt;th&gt;3&lt;&#x2F;th&gt;&lt;th&gt;4&lt;&#x2F;th&gt;&lt;th&gt;5&lt;&#x2F;th&gt;&lt;th&gt;6&lt;&#x2F;th&gt;&lt;th&gt;7&lt;&#x2F;th&gt;&lt;th&gt;8&lt;&#x2F;th&gt;&lt;th&gt;9&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;p&gt;此时我们查询&lt;code&gt;charmer&lt;&#x2F;code&gt;是否存在，计算&lt;code&gt;Fnv=12&lt;&#x2F;code&gt;，&lt;code&gt;Murmur=10&lt;&#x2F;code&gt;，bitmap中存在0，因此&lt;strong&gt;不存在&lt;&#x2F;strong&gt;。&lt;&#x2F;p&gt;
&lt;p&gt;再查询&lt;code&gt;hello&lt;&#x2F;code&gt;是否存在，计算&lt;code&gt;Fnv=6&lt;&#x2F;code&gt;，&lt;code&gt;Murmur=0&lt;&#x2F;code&gt;，bitmap中都为1，因此&lt;strong&gt;可能存在&lt;&#x2F;strong&gt;，需要访问磁盘，得知真的存在。&lt;&#x2F;p&gt;
&lt;p&gt;再查询&lt;code&gt;zaslf&lt;&#x2F;code&gt;是否存在，计算&lt;code&gt;Fnv=7&lt;&#x2F;code&gt;，&lt;code&gt;Murmur=1&lt;&#x2F;code&gt;，bitmap都为1，因此&lt;strong&gt;可能存在&lt;&#x2F;strong&gt;，需要访问磁盘，得知它不存在。这次磁盘访问就是false positive带来的坏影响，多余的磁盘访问。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;oliverdding&#x2F;imaw.io&#x2F;main&#x2F;bloom-filter-speed-up-answers.drawio.svg&quot; alt=&quot;布隆过滤器加速查询&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;shu-xue-tui-dao&quot;&gt;数学推导&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;k取何值时，false positive发生概率最小，此时概率为？&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;由于hash函数“选择”&lt;code&gt;bitmap&lt;&#x2F;code&gt;的位置是随机的，因此对于长度为m的&lt;code&gt;bitmap&lt;&#x2F;code&gt;而言，插入一个值时某个位被置1、0的概率分别是$P(1) = \frac{1}{m}$、$P(0) = 1 - \frac{1}{m}$&lt;&#x2F;p&gt;
&lt;p&gt;当k个hash函数置位后，对于任意一个位，仍然是0的概率是$$P&#x27;(0)=P(0)^{k}=(1 - \frac{1}{m})^{k}$$&lt;&#x2F;p&gt;
&lt;p&gt;对于n个key插入后，对于任意一个位，仍然是0的概率是$$P&#x27;&#x27;(0)=P&#x27;(0)^{n}=(1 - \frac{1}{m})^{kn}$$&lt;&#x2F;p&gt;
&lt;p&gt;由于有自然对数e的计算公式$$\lim_{x \to \infty}{(1-\frac{1}{x})^{-x}}=e$$&lt;&#x2F;p&gt;
&lt;p&gt;我们可以&lt;strong&gt;近似&lt;&#x2F;strong&gt;计算$P&#x27;&#x27;(0)$得到$$P&#x27;&#x27;(0)=((1-\frac{1}{m})^{-m})^{-\frac{kn}{m}}\approx{}e^{-\frac{kn}{m}}$$&lt;&#x2F;p&gt;
&lt;p&gt;因此，对于任意一个位，其被置1的概率是$$P&#x27;&#x27;(1)=1-P&#x27;&#x27;(0)\approx{}1-e^{-\frac{kn}{m}}$$&lt;&#x2F;p&gt;
&lt;p&gt;当alse positive发生时，是指它的k个hash函数得到的位置都为1。由于k个hash函数相互独立，我们可以计算出alse positive的概率为$$\varepsilon=(1-(1-\frac{1}{m})^{kn})^{k}\approx{}(1-e^{-\frac{kn}{m}})^{k}$$&lt;&#x2F;p&gt;
&lt;p&gt;由于m、n是用户给定的值，唯一变量就是k，我们需要指定k的值去最小化alse positive概率。&lt;&#x2F;p&gt;
&lt;p&gt;令$p=e^{-\frac{kn}{m}}$以及自然对数公式，我们有$$\varepsilon=(1-p)^{k}=e^{kln(1-p)}$$&lt;&#x2F;p&gt;
&lt;p&gt;此时变更为最小的$g=kln(1-p)$&lt;&#x2F;p&gt;
&lt;p&gt;无中生有下得到$$g=kln{}(1-p)=-\frac{m}{n}ln(e^{-\frac{kn}{m}})ln(1-p)=-\frac{m}{n}ln(p)ln(1-p)$$&lt;&#x2F;p&gt;
&lt;p&gt;根据对称性原理得知当$p=\frac{1}{2}$时g取得最小，此时有$$k=\frac{m}{n}ln(2)$$&lt;&#x2F;p&gt;
&lt;p&gt;插入回$$\varepsilon=(1-p)^{k}$$得到alse positive的最小值为$$\varepsilon_{min}=(\frac{1}{2})^{k}\approx{}(0.6185)^{\frac{m}{n}}$$&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ying-yong&quot;&gt;应用&lt;&#x2F;h2&gt;
&lt;p&gt;那么如何在项目中使用bloom filter呢？&lt;&#x2F;p&gt;
&lt;h3 id=&quot;yi-zhi-n-he-varepsilon&quot;&gt;已知$n$和$\varepsilon$&lt;&#x2F;h3&gt;
&lt;p&gt;$n$由系统输入决定，$\varepsilon$则是开发者平衡内存使用和性能的选择，因此可以通过传入这两个变量自动计算剩下的值。&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;根据公式$m=\lceil{}-\frac{nln(\varepsilon)}{(ln(2))^2}\rceil$计算m的值&lt;&#x2F;li&gt;
&lt;li&gt;根据公式$k=\lceil{}-log_2(\varepsilon)\rceil$计算k的值&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;que-xian&quot;&gt;缺陷&lt;&#x2F;h2&gt;
&lt;p&gt;基础bloom filter有着自己的局限性，因此出现了许多变种，它们为了特殊场景作出不同的定制，增加一定开销换取更多功能：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;&#x2F;posts&#x2F;bloom-filter-2&#x2F;&quot;&gt;可扩展布隆过滤器&lt;&#x2F;a&gt;：基础bloom filter必须预先知道元素数量以分配空间&lt;&#x2F;li&gt;
&lt;li&gt;计数布隆过滤器：基础bloom filter无法删除元素，只能重建&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;&#x2F;posts&#x2F;count-min-sketch&#x2F;&quot;&gt;Count-Min Sketch&lt;&#x2F;a&gt;：利用计数布隆过滤器相同变体实现各基数数量统计能力&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;can-kao&quot;&gt;参考&lt;&#x2F;h2&gt;
&lt;div class=&quot;footnote-definition&quot; id=&quot;1&quot;&gt;&lt;sup class=&quot;footnote-definition-label&quot;&gt;1&lt;&#x2F;sup&gt;
&lt;p&gt;Space&#x2F;Time Trade-offs in Hash Coding with Allowable Errors
&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#2&quot;&gt;2&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;: Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol 
&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#3&quot;&gt;3&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;: Network Applications of Bloom Filters: A Survey
&lt;sup class=&quot;footnote-reference&quot;&gt;&lt;a href=&quot;#4&quot;&gt;4&lt;&#x2F;a&gt;&lt;&#x2F;sup&gt;: Bloom Filters by Example. https:&#x2F;&#x2F;llimllib.github.io&#x2F;bloomfilter-tutorial&#x2F;&lt;&#x2F;p&gt;
&lt;&#x2F;div&gt;
</description>
        </item>
    </channel>
</rss>
