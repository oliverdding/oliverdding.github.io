<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
      <title>Aurora - Translations</title>
        <link>https://charmer.netlify.app</link>
        <description>Sidere mens eadem mutato</description>
        <generator>Zola</generator>
        <language>zh</language>
        <atom:link href="https://charmer.netlify.app/categories/translations/rss.xml" rel="self" type="application/rss+xml"/>
        <lastBuildDate>Sun, 04 Jul 2021 12:42:17 +0800</lastBuildDate>
        <item>
            <title>翻译：RDD编程指导</title>
            <pubDate>Sun, 04 Jul 2021 12:42:17 +0800</pubDate>
            <link>https://charmer.netlify.app/posts/translation-rdd-programming-guide/</link>
            <guid>https://charmer.netlify.app/posts/translation-rdd-programming-guide/</guid>
            <description>&lt;h2 id=&quot;zong-lan&quot;&gt;总览&lt;&#x2F;h2&gt;
&lt;p&gt;每个spark应用包含一个驱动程序，两个职责:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;运行用户的main函数&lt;&#x2F;li&gt;
&lt;li&gt;在集群上执行一些并行操作&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;div class=&quot;mermaid is-flex is-justify-content-center is-align-items-center&quot;&gt;graph TD;
  subgraph spark application;
  core[driver program] -.职责1.-&amp;gt; act1(run user&amp;#x27;s main function);
  core[driver program] -.职责2.-&amp;gt; act2(execute various parallel operations);
  end&lt;&#x2F;div&gt;
&lt;p&gt;同样，spark提供了两层抽象:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;resilient distributed dataset(RDD): 一组元素的集合，分段地存储在集群不同节点上，并且支持并行操作。
&lt;ol&gt;
&lt;li&gt;可以是分布式文件系统中的一个文件&lt;&#x2F;li&gt;
&lt;li&gt;可以是driver program中的一个scala集合&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;shared variables: 可以在并行操作中使用。
&lt;ol&gt;
&lt;li&gt;broadcast类型变量: 用于在不同节点地内存中存储一个值&lt;&#x2F;li&gt;
&lt;li&gt;accumulators类型变量: 只支持“add“操作的变量&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;chu-shi-hua-spark&quot;&gt;初始化spark&lt;&#x2F;h2&gt;
&lt;ol&gt;
&lt;li&gt;初始化&lt;code&gt;SparkConf&lt;&#x2F;code&gt;，包含目标应用的信息&lt;&#x2F;li&gt;
&lt;li&gt;使用&lt;code&gt;SparkConf&lt;&#x2F;code&gt;初始化&lt;code&gt;SparkContext&lt;&#x2F;code&gt;以连接cluster&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;resilient-distributed-datasets-rdds&quot;&gt;Resilient Distributed Datasets (RDDs)&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;parallelized-collections&quot;&gt;Parallelized Collections&lt;&#x2F;h3&gt;
&lt;p&gt;调用&lt;code&gt;SparkContext&lt;&#x2F;code&gt;的&lt;code&gt;parallelize&lt;&#x2F;code&gt;方法，传入一个普通集合以生产一个并行集合，之后便可以并行操作。&lt;&#x2F;p&gt;
&lt;p&gt;此外，还可以控制并行集合的分区数量，spark会为并行集合的每一个分区运行一个任务。一般spark会自动设置合适的分区，当然也可以&lt;code&gt;parallelize&lt;&#x2F;code&gt;方法控制。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;external-datasets&quot;&gt;External Datasets&lt;&#x2F;h3&gt;
&lt;p&gt;spark可以从hadoop支持的任何数据源创建RDD，并且支持hadoop支持的所有&lt;code&gt;inputFormat&lt;&#x2F;code&gt;，包括text files、SequenceFiles。&lt;&#x2F;p&gt;
&lt;p&gt;spark读取文件(&lt;code&gt;textFile&lt;&#x2F;code&gt;方法)的一些提示:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;使用本地文件系统上的文件，，比如保证每个node相同路径上也有这个文件。&lt;&#x2F;li&gt;
&lt;li&gt;spark所有的文件读取的方法，支持目录、压缩文件以及通配符。&lt;&#x2F;li&gt;
&lt;li&gt;可选的第二个参数用于控制分块数量。默认情况下，spark会根据文件block大小创建分块(hdfs下默认是128M)。&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;除了&lt;code&gt;textFile&lt;&#x2F;code&gt;外，spark还提供了其它格式的数据读取方法:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;SparkContext.wholeTextFiles&lt;&#x2F;code&gt;可以读取包含大量小文件的目录，并以文件名:文件内容对的方式返回。&lt;&#x2F;li&gt;
&lt;li&gt;对于&lt;code&gt;SequenceFile&lt;&#x2F;code&gt;，使用&lt;code&gt;SparkContext.sequenceFile[K, V]&lt;&#x2F;code&gt;方法读取，K、V是文件中key和value的类型，并且应该是hadoop的&lt;code&gt;Writable&lt;&#x2F;code&gt;接口的实现者。&lt;&#x2F;li&gt;
&lt;li&gt;对于hadoop的&lt;code&gt;inputFormat&lt;&#x2F;code&gt;，可以使用&lt;code&gt;SparkContext.hadoopRDD&lt;&#x2F;code&gt;方法。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;code&gt;saveAsObjectFile&lt;&#x2F;code&gt;和&lt;code&gt;objectFile&lt;&#x2F;code&gt;方法用于保存RDD。&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h3 id=&quot;rddde-cao-zuo&quot;&gt;RDD的操作&lt;&#x2F;h3&gt;
&lt;p&gt;RDD支持两种类型的操作:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;转换(transformations): 从现有数据集中创建新的数据集&lt;&#x2F;li&gt;
&lt;li&gt;计算(actions): 在某个数据集上运行并获取结果&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;举例，map操作就是转换，传入某个数据集的每个元素，返回代表着新数据集的RDD。reduce就是计算，聚合RDD中所有元素，返回最终结果到driver program。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;spark中所有的转换操作都是lazy的&lt;&#x2F;strong&gt;，也就是说不会在调用时立马计算，而是在计算操作被执行时才去计算。&lt;&#x2F;p&gt;
&lt;p&gt;默认情况下，每次运行计算，所有转换过的RDD都会被重复计算。但是可以配置spark缓存。&lt;&#x2F;p&gt;
&lt;h4 id=&quot;ji-chu&quot;&gt;基础&lt;&#x2F;h4&gt;
&lt;p&gt;举例说明(网站上例子):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282828;color:#fdf4c1aa;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;color:#8ec07c;&quot;&gt;JavaRDD&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8ec07c;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; lines &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fe8019;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; sc.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt;textFile(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b8bb26;&quot;&gt;&amp;quot;data.txt&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt;)&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8ec07c;&quot;&gt;JavaRDD&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8ec07c;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; lineLengths &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fe8019;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; lines.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt;map(s &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fa5c4b;&quot;&gt;-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt; s.length())&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fa5c4b;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; totalLength &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fe8019;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; lineLengths.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt;reduce((a, b) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fa5c4b;&quot;&gt;-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt; a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fe8019;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt; b)&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;第一行定义了从文件中获取的RDD。注意，并未实际读取，而只是一个指针。&lt;&#x2F;p&gt;
&lt;p&gt;第二行对这个文件进行map转换操作。注意，因为懒加载，并未实际处理。&lt;&#x2F;p&gt;
&lt;p&gt;最后一行执行reduce计算操作。此时spark将计算任务分解为一个个task，运行在集群不同的节点上。每个节点在其part上运行map、reduce操作，并返回结果给driver program。&lt;&#x2F;p&gt;
&lt;p&gt;通过在reduce前调用&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282828;color:#fdf4c1aa;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span&gt;lineLengths.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt;persist(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8ec07c;&quot;&gt;StorageLevel&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt;.MEMORY_ONLY())&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;可以将&lt;code&gt;lineLengths&lt;&#x2F;code&gt;RDD缓存起来，之后重复调用reduce时不必重复map。&lt;&#x2F;p&gt;
&lt;h4 id=&quot;han-shu-chuan-di&quot;&gt;函数传递&lt;&#x2F;h4&gt;
&lt;p&gt;spark的api严重依赖于&lt;strong&gt;传递函数&lt;&#x2F;strong&gt;的方式执行任务。具体请看官方网站。&lt;&#x2F;p&gt;
&lt;h4 id=&quot;li-jie-bi-bao&quot;&gt;理解闭包&lt;&#x2F;h4&gt;
&lt;p&gt;spark最难理解的是在群集中执行代码时&lt;em&gt;变量的范围&lt;&#x2F;em&gt;、&lt;em&gt;生命周期&lt;&#x2F;em&gt;和&lt;em&gt;方法&lt;&#x2F;em&gt;。&lt;&#x2F;p&gt;
&lt;p&gt;最容易犯的错就是在变量的作用域外调用RDD的operations。&lt;&#x2F;p&gt;
&lt;h5 id=&quot;li-zi&quot;&gt;例子&lt;&#x2F;h5&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282828;color:#fdf4c1aa;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;color:#fa5c4b;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; counter &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fe8019;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d3869b;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8ec07c;&quot;&gt;JavaRDD&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8ec07c;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; rdd &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fe8019;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; sc.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt;parallelize(data)&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#928374;&quot;&gt;&#x2F;&#x2F; Wrong: Don&amp;#39;t do this!!
&lt;&#x2F;span&gt;&lt;span&gt;rdd.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt;foreach(x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fa5c4b;&quot;&gt;-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt; counter &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fe8019;&quot;&gt;+=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt; x)&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt;println(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b8bb26;&quot;&gt;&amp;quot;Counter value: &amp;quot; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#fe8019;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span style=&quot;color:#fdf4c1;&quot;&gt; counter)&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;这段代码的结果取决于是否运行在同一个JVM中。也就是说，是本地运行 (–master = local[n]) 还是集群运行（spark-submit）。&lt;&#x2F;p&gt;
&lt;p&gt;运行jobs时，spark会将RDD的operations分解为tasks，交由一个个executor执行。而在执行前，spark会构建task的闭包。闭包是对RDD执行计算时必须要用到的变量(例子中就是counter)和方法(例子中就是foreach())，会被序列化并发送给各个executor。&lt;&#x2F;p&gt;
&lt;p&gt;在集群模式，闭包使用到的变量会被拷贝进闭包，然后发送给executor执行，executo后续会对闭包内的counter进行处理，而不是driver program中的counter。也就是说，修改并不成功，最终结果还是0。而local模式则相反，task运行在相同JVM，counter的引用就是原变量，因此可以得到正确结果。&lt;&#x2F;p&gt;
&lt;p&gt;在这个场景中，为了得到正确结果，spark定义了accumulator类型变量，提供了跨节点累加值的机制。&lt;&#x2F;p&gt;
&lt;h5 id=&quot;shu-chu-rddyuan-su&quot;&gt;输出RDD元素&lt;&#x2F;h5&gt;
&lt;p&gt;RDD的另一种常见错误用法是通过forEach(println)和map(println)输出元素。在单例模式下正常运作，但是在集群模式下，打印的值会输出到executor的标准输出，而不是driver program的，因此也就看不到元素内容。&lt;&#x2F;p&gt;
&lt;p&gt;为了正确获取元素内容，需要先调用&lt;code&gt;collect()&lt;&#x2F;code&gt;函数以将元素收集到driver program，然后再调用输出函数。但是这容易造成OOM。另一种方案是&lt;code&gt;take()&lt;&#x2F;code&gt;函数，只收集一定数量的元素。&lt;&#x2F;p&gt;
&lt;h4 id=&quot;key-valuedui&quot;&gt;Key-Value对&lt;&#x2F;h4&gt;
&lt;p&gt;虽然大多数Spark操作都适用于包含任何类型对象的RDDs，但有几个特殊的操作只适用于键值对的RDDs。最常见的是分布式 “洗牌(shuffle)“操作，如按键分组或聚合元素。&lt;&#x2F;p&gt;
&lt;h4 id=&quot;transformations&quot;&gt;Transformations&lt;&#x2F;h4&gt;
&lt;p&gt;请到网页查看: &lt;a rel=&quot;noopener nofollow noreferrer&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;spark.apache.org&#x2F;docs&#x2F;latest&#x2F;rdd-programming-guide.html#transformations&quot;&gt;transformations&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;actions&quot;&gt;Actions&lt;&#x2F;h4&gt;
&lt;p&gt;请到网页查看: &lt;a rel=&quot;noopener nofollow noreferrer&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;spark.apache.org&#x2F;docs&#x2F;latest&#x2F;rdd-programming-guide.html#actions&quot;&gt;actions&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;xi-pai-cao-zuo&quot;&gt;洗牌操作&lt;&#x2F;h4&gt;
&lt;p&gt;Spark中的某些操作会触发一个被称为洗牌的事件。洗牌是Spark重新分配数据的机制，使其在不同的分区中以不同的方式分组。这通常涉及跨执行器和机器的数据复制，使洗牌成为一个复杂而昂贵的操作。&lt;&#x2F;p&gt;
&lt;h5 id=&quot;bei-jing&quot;&gt;背景&lt;&#x2F;h5&gt;
&lt;p&gt;为了解释洗牌操作，用&lt;code&gt;reduceByKey&lt;&#x2F;code&gt;来演示，这个方法生成新的RDD，将所有于key关联的value合并为一个touple。最麻烦的地方是，不是所有和key关联的value在同一个分区、甚至节点。不同executor需要合作以得到结果。&lt;&#x2F;p&gt;
&lt;p&gt;在spark中，不会为了某个operation去交换分区。在计算过程中，一个task就只操作一个分区；因此，为了规划&lt;code&gt;reduceByKey&lt;&#x2F;code&gt;这个reduce任务，spark需要一个&lt;strong&gt;all-to-all&lt;&#x2F;strong&gt;操作: 从所有分区读取所有key对应的所有的的value，然后跨集群聚集所有value以计算每个key对应的结果集。这就是“洗牌“。&lt;&#x2F;p&gt;
&lt;p&gt;洗牌后排序看网站&lt;&#x2F;p&gt;
&lt;h5 id=&quot;xing-neng-sun-shi&quot;&gt;性能损失&lt;&#x2F;h5&gt;
&lt;p&gt;洗牌操作非常消耗资源，需要磁盘I&#x2F;O、序列化和网络I&#x2F;O。为了聚集洗牌需要的数据，spark会启动一系列task，“map任务“用于组织数据，“reduce任务“用于聚合数据。&lt;&#x2F;p&gt;
&lt;p&gt;在spark内部，洗牌操作执行时，每个“map任务“会将结果保存在内存中(直到溢出，溢出则分块写入外存)，然后根据分区顺序排序后写入单一的文件内; “reduce任务“会读取这个文件。&lt;&#x2F;p&gt;
&lt;p&gt;洗牌还会产生大量临时文件，直到RDD生命周期结束并且相关资源被垃圾回收。注意，垃圾回收会在任务停止之后很久很久才进行，也就是说，长期的的spark job会导致大量存储消耗。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;chi-jiu-cun-chu&quot;&gt;持久存储&lt;&#x2F;h3&gt;
&lt;p&gt;RDD可以被持久化存储，每个节点都会将它计算的分区存储在内存中，并在该数据集（或由其衍生的数据集）上的其他操作中重复使用。&lt;&#x2F;p&gt;
&lt;p&gt;使用方法&lt;code&gt;persist()&lt;&#x2F;code&gt;或者&lt;code&gt;cache()&lt;&#x2F;code&gt;使RDD持久化。&lt;&#x2F;p&gt;
&lt;p&gt;除此之外，持久化存储级别是可以选择的，默认是内存。具体请看&lt;a rel=&quot;noopener nofollow noreferrer&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;spark.apache.org&#x2F;docs&#x2F;latest&#x2F;rdd-programming-guide.html#rdd-persistence&quot;&gt;网站&lt;&#x2F;a&gt;。&lt;&#x2F;p&gt;
&lt;h4 id=&quot;xuan-ze-chi-jiu-hua-cun-chu-ji-bie&quot;&gt;选择持久化存储级别&lt;&#x2F;h4&gt;
&lt;p&gt;持久化存储关系到内存和CPU的效率，官方给出选择方法，具体请看&lt;a rel=&quot;noopener nofollow noreferrer&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;spark.apache.org&#x2F;docs&#x2F;latest&#x2F;rdd-programming-guide.html#which-storage-level-to-choose&quot;&gt;网站&lt;&#x2F;a&gt;。&lt;&#x2F;p&gt;
&lt;h4 id=&quot;yi-chu-shu-ju&quot;&gt;移除数据&lt;&#x2F;h4&gt;
&lt;p&gt;Spark监控缓存的使用，并依照LRU算法丢弃旧缓存。可以通过&lt;code&gt;unpersist()&lt;&#x2F;code&gt;方法取消缓存，默认异步完成；可以通过传入&lt;code&gt;blocking=true&lt;&#x2F;code&gt;控制为同步方式。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;gong-xiang-bian-liang&quot;&gt;共享变量&lt;&#x2F;h2&gt;
&lt;p&gt;Spark操作的运行类似与函数调用，值传递。为了实现在节点运行的操作改变driver program的数值，spark提供了两种变量类型：broadcast variable、accumulator。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;broadcast-variables&quot;&gt;Broadcast Variables&lt;&#x2F;h3&gt;
&lt;p&gt;广播变量可以让每个节点保存一个只读变量在本地，而不是每次运行task传入。用于高效地给每个节点一些较大数据集。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;accumulators&quot;&gt;Accumulators&lt;&#x2F;h3&gt;
&lt;p&gt;累加器是只通过关联和换元操作 “只增“的变量，因此可以有效地支持并行，可以用来实现计数器（如MapReduce）或总和。Spark原生支持数字类型的累加器，程序员可以增加对新类型的支持。&lt;&#x2F;p&gt;
</description>
        </item>
    </channel>
</rss>
